{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -q\n",
    "from transformers import LongformerForMultipleChoice, LongformerTokenizerFast, AdamW, Trainer, TrainingArguments, RobertaForMultipleChoice, RobertaTokenizerFast\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score \n",
    "import copy\n",
    "from transformers.tokenization_utils_base import PaddingStrategy, TruncationStrategy\n",
    "from prettytable import PrettyTable\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the train_data\n",
    "train_data = pd.read_csv('./train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(dataframe: pd.DataFrame):\n",
    "    \"\"\"A simple function \n",
    "    to print the label distributions in a panada dataframe\n",
    "    \n",
    "    Input: a panda dataframe\n",
    "    Outut : None. It just print the label distribution table.\"\"\"\n",
    "    \n",
    "    table = PrettyTable([\"Labels\", \"Distribution\"])\n",
    "    t= dataframe['label'].value_counts(normalize = True)\n",
    "    for name, count in zip(t.index, t.values):\n",
    "        table.add_row([name, round(count,4)])\n",
    "\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDatset(Dataset):\n",
    "    \n",
    "    \"\"\"This class create the dataset needed to train a multiplechoice Model.\n",
    "    It gets a panda dataframe and a tokenizer,which gets the text and the choices and provides \n",
    "    the tokenized input in the shape of [number_of_choices, length_of_the_text] in following format \n",
    "\n",
    "                    <s>text</s></s>choice</s><pad> \n",
    "                    \n",
    "    and it provides a python Dataset\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        dataframe: a panda dataframe containing the examples\n",
    "        tokenizer_name: Tokenizer model name. Default is 'Longformer'\n",
    "        tokenizer_pth: Path to load the tokenizer from.  Default is 'allenai/longformer-base-4096'\n",
    "        mode: A string, 'train' or 'test', to determine if the dataset has labels or not. Default is 'train'\n",
    "        max_length: The longest possible sequences. the default value is 512. \n",
    "    \n",
    "    \n",
    "    Return:\n",
    "    \n",
    "        A python dataset, which returns a dictionary containing Input_ids, Attention_mask and Label.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe: pd.DataFrame, tokenizer_name: str='Longformer',\n",
    "                 tokenizer_pth: str= 'allenai/longformer-base-4096', mode: str='train', max_length: int =512):\n",
    "        \"\"\"Read the dataframe row by row, tokenized them and store them in a list\n",
    "        \n",
    "        Arguments:\n",
    "        \n",
    "            dataframe:  panda datafrmae\n",
    "            tokenizer_name\n",
    "            tokenizer_pth\n",
    "            mode\n",
    "        \n",
    "        Attributes:\n",
    "            \n",
    "            self.instances: a list to store the instances in the dataframe after tokenization as\n",
    "            a tuple (tokenized_input, label)\"\"\"\n",
    "        \n",
    "        \n",
    "        tokenizer_models = {'Longformer': LongformerTokenizerFast,\n",
    "                           'Roberta': RobertaTokenizerFast \n",
    "                           }\n",
    "        \n",
    "        tokenizer = tokenizer_models[tokenizer_name].from_pretrained(tokenizer_pth)\n",
    "        \n",
    "        self.instances = []\n",
    "        self.mode = mode\n",
    "        for index, row in dataframe.iterrows():\n",
    "            choices = self.extract_choices(row)\n",
    "            tokenized_input = tokenizer([row['text']]*len(choices), choices, max_length=max_length,\n",
    "                                        return_tensors='pt', padding=True, truncation=True)\n",
    "            \n",
    "            if self.mode == 'train':\n",
    "                label = [self.get_label(row['label'])]\n",
    "            else:\n",
    "                label = ''\n",
    "            self.instances.append((tokenized_input, label))\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"\" Returns a specific item in the dataset\n",
    "        \n",
    "        Arguments:\n",
    "            index: the item's index\n",
    "        \n",
    "        Returns:\n",
    "            a dictionary containing input_ids, attention_mask and label\"\"\"\n",
    "        \n",
    "        tokenized_texts, label = self.instances[index]\n",
    "        if self.mode == 'train':\n",
    "            label_pt = torch.tensor(label)\n",
    "            tokenized_texts['label'] = label_pt\n",
    "\n",
    "        return tokenized_texts\n",
    "    \n",
    "    def __len__(self):\n",
    "        '''returns length of the dataset'''\n",
    "        return len(self.instances)\n",
    "            \n",
    "    def extract_choices(self, instance: pd.core.series.Series):\n",
    "        \"\"\"Get an row from the panda dataframe and returns the possible choices.\n",
    "        \n",
    "        Arguments:\n",
    "            \n",
    "            instance: a panda dataframe row\n",
    "            \n",
    "        Returns:\n",
    "            list: a list of possible choices\n",
    "        \"\"\"\n",
    "        choices = []\n",
    "        for i in range(1,7):\n",
    "            choice = instance['choice'+str(i)]\n",
    "            if type(choice) == float:\n",
    "#                 choices.append(str(choice))\n",
    "                continue\n",
    "            else:\n",
    "                choices.append(choice)\n",
    "        return choices\n",
    "    \n",
    "    def get_label(self, label: str):\n",
    "        '''Gets a string and map it to its numerical label\n",
    "        \n",
    "        Arguments:\n",
    "            label: A string of the label\n",
    "        \n",
    "        Return:\n",
    "            list: a single item list containin the mapped label'''\n",
    "        return{\n",
    "            'choice1': 0,\n",
    "            'choice2': 1,\n",
    "            'choice3': 2,\n",
    "            'choice4': 3,\n",
    "            'choice5': 4,\n",
    "            'choice6': 5,\n",
    "        }[label]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Testing if the MultiQ_Dataset works propely\n",
    "train_dataset = MultiDatset(train_data.iloc[:10], 'Longformer')\n",
    "train_dataset[5]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the provided dataset is very big, we just use the first 10000 instances and then breake the extracted part to 70% and 30% splits for training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split , val_split = train_test_split(train_data[:10000],\n",
    "                                           test_size=0.3,\n",
    "                                           random_state=2021) \n",
    "train_dataset = MultiDatset(train_split)\n",
    "val_dataset = MultiDatset(val_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModel():\n",
    "    \n",
    "    \"\"\"The Multi choice model which gets a transformers multi choice model (A language model with a classifier on top)\n",
    "    and train the model on the specified dataset.\n",
    "    \n",
    "    Arguments:\n",
    "        model_name: It is a string specifing which based model you would like to use. options: Longformer, Roberta\n",
    "        model_name: A string poiting out to the location of the model.\"\"\"\n",
    "    \n",
    "    def __init__(self,train_args: transformers.TrainingArguments, model_name: str = 'Longformer',\n",
    "                 model_path: str = 'allenai/longformer-base-4096'):\n",
    "        '''Initialize the model'''\n",
    "        model_options = {'Longformer': LongformerForMultipleChoice, \n",
    "                'Roberta': RobertaForMultipleChoice}\n",
    "        self.model = model_options[model_name].from_pretrained(model_path)\n",
    "        self.train_args = train_args\n",
    "    \n",
    "    def train(self, train_dataset: MultiDatset, val_dataset: MultiDatset):\n",
    "        \n",
    "        \"\"\"This function prepare and start a Transformers.Trainer by getting transformer.TraininggArguments,\n",
    "        And training dataset\n",
    "        \n",
    "        Arguments: \n",
    "            args: Transfromers.TrainingArguments\n",
    "            train_dataset: A MultiC_Dataset dataset containing training instances\n",
    "            eval_dataset: A MultiC_Dataset dataset containing validation instances \n",
    "        Returns:\n",
    "        \n",
    "            It return a Trainer instance. \"\"\"\n",
    "        \n",
    "        trainer = Trainer(model=self.model,\n",
    "                        args=self.train_args,\n",
    "                        train_dataset=train_dataset,         \n",
    "                        eval_dataset=val_dataset,             \n",
    "                        compute_metrics=self.compute_metrics)\n",
    "        return trainer\n",
    "        \n",
    "        \n",
    "    def compute_metrics(self, pred):\n",
    "        '''Calculate the evaluation metrics'''\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        f1micro = f1_score(labels, preds, average='micro')\n",
    "        f1macro =  f1_score(labels, preds, average='macro')\n",
    "        precision = precision_score(labels,preds, average='macro')\n",
    "        recall = recall_score(labels, preds, average='macro')\n",
    "        print(classification_report(labels,preds))\n",
    "        mbe = self.MBE(labels, preds)\n",
    "        return {\n",
    "          'accuracy': acc,\n",
    "            'f1micro' : f1micro,\n",
    "            'f1macro' : f1macro,\n",
    "            'precision' : precision,\n",
    "            'recall' : recall,\n",
    "            'MBE': mbe\n",
    "          }\n",
    "    \n",
    "    def MBE(self, y_true, y_pred):\n",
    "        '''\n",
    "        Parameters:\n",
    "            y_true (array): Array of observed values\n",
    "            y_pred (array): Array of prediction values\n",
    "\n",
    "        Returns:\n",
    "            mbe (float): Biais score\n",
    "        '''\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_true = y_true.reshape(len(y_true),1)\n",
    "        y_pred = y_pred.reshape(len(y_pred),1)   \n",
    "        diff = (y_true-y_pred)\n",
    "        mbe = diff.mean()\n",
    "        return mbe\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now We just create an instance of TraininArguments and pass it to MultiC_Model. Then by creating a trainer object, start training and then predict on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=1,  # batch size per device during training\n",
    "    per_device_eval_batch_size=1,   # batch size for evaluation\n",
    "    warmup_steps=100,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=7,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    gradient_accumulation_steps=8,\n",
    "    seed = 12,   \n",
    ")\n",
    "\n",
    "model = MultiModel(training_args,model_name='Longformer')\n",
    "trainer = model.train(train_dataset, val_dataset)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('longformer_multiplechoice10000_512.pth/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = MultiDatset(train_data[10001:20000])\n",
    "trainer.predict(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(results, path):\n",
    "    '''gets a numpy array of predictions and after applying a softmax function, it will write the results.'''\n",
    "    softmax= nn.Softmax(dim=0)\n",
    "    columns = ['idx', 'choice1', 'choice2', 'choice3', 'choice4', 'choice5', 'choice6']\n",
    "    logits = []\n",
    "    for index, row in enumerate(results[0]):\n",
    "        tensor_row = torch.tensor(row, dtype=float)\n",
    "        logits.append([index]+softmax(tensor_row).tolist())\n",
    "        \n",
    "    with open(path, 'w+', encoding='utf-8') as f:\n",
    "        write = csv.writer(f)\n",
    "        write.writerow(columns)\n",
    "        write.writerows(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./test.csv')\n",
    "test_dataset = MultiDatset(test_data,mode='test', max_length= 4096)\n",
    "results = trainer.predict(test_dataset)\n",
    "write_csv(results[0], './results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
